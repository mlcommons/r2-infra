<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MLPerf Training Benchmark Data Download</title>
    
    <!-- Favicons -->
    <link rel="apple-touch-icon" sizes="180x180" href="https://r2-infra.mlcommons-storage.org/central/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://r2-infra.mlcommons-storage.org/central/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://r2-infra.mlcommons-storage.org/central/favicon/favicon-16x16.png">
    <link rel="manifest" href="https://r2-infra.mlcommons-storage.org/central/favicon/site.webmanifest">
    
    <!-- Load shared CSS and JS from central bucket -->
    <link rel="stylesheet" href="https://r2-infra.mlcommons-storage.org/central/shared.css">
    <script src="https://r2-infra.mlcommons-storage.org/central/shared.js"></script>
    <!-- Load shared header & quick-start as early as possible -->
    <script defer>
      document.addEventListener('DOMContentLoaded', () => {
        fetch('https://r2-infra.mlcommons-storage.org/central/shared-content.html')
          .then(r => r.text())
          .then(html => {
            const tmp = document.createElement('div');
            tmp.innerHTML = html;
            const header = tmp.querySelector('.header-strip');
            const quick  = tmp.querySelector('#quick-start-section');
            if (header) document.getElementById('header-placeholder').innerHTML = header.outerHTML;
            const holder=document.getElementById('quick-start-placeholder');
            if(quick && holder){ holder.replaceWith(quick); }
            if (typeof initializeCopyButtons === 'function') initializeCopyButtons();
          })
          .catch(err => console.error('Failed to load shared content:', err));
      });
    </script>
</head>
<body>
    <!-- Header will be loaded from shared content -->
    <div id="header-placeholder"></div>
    
    <div class="page-content">
        <div class="container">
            <h1>MLPerf Training Benchmark Data Download</h1>
            
            

            <!-- Quick-Start skeleton to reserve space (visibility hidden) -->
            <div id="quick-start-placeholder" style="visibility:hidden">
                <div class="alert alert-info">
                    <strong>Quick Start:</strong> Copy one of the commands below and run it in your terminal to download the indicated dataset.
                </div>
            </div>
        
            <h2>Available Downloads</h2>

            <details id="dlrm-v2-benchmark"><summary><h3>DLRM v2 Benchmark</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">Criteo 4TB multi-hot dataset (reference format)</h3>
    <p class="dataset-description">Criteo Click Logs dataset preprocessed to create a synthetic multi-hot dataset in reference format (~4.0TB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/dlrmv2-preprocessed-criteo-click-logs-reference.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Criteo 4TB multi-hot dataset (HugeCTR format)</h3>
    <p class="dataset-description">Criteo Click Logs dataset preprocessed to create a synthetic multi-hot dataset in HugeCTR format (~4.0TB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/dlrmv2-preprocessed-criteo-click-logs.uri</code>
        </div>
    </div>
</div>
</details>
<details id="deepseekv3-benchmark"><summary><h3>DeepSeekv3 Benchmark</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">DeepSeekv3 BF16 Checkpoint</h3>
    <p class="dataset-description">BF16 weights-only checkpoint in HuggingFace format obtained by loading https://huggingface.co/deepseek-ai/DeepSeek-V3-Base, training for &lt;#-trained-samples&gt; samples until tokens are balanced using NVIDIA Nemo framework and converting to HuggingFace format. </p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/deepseekv3_checkpoint_bf16.uri</code>
        </div>
    </div>
</div>
</details>
<details id="flux-1-benchmark"><summary><h3>FLUX.1 Benchmark</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">CC12M preprocessed dataset</h3>
    <p class="dataset-description">Conceptual 12M preprocessed dataset (~2.4TB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/flux-1-cc12m-preprocessed.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">COCO preprocessed dataset</h3>
    <p class="dataset-description">Common Objects in Context preprocessed dataset (~65GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/flux-1-coco-preprocessed.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">CC12M dataset</h3>
    <p class="dataset-description">Conceptual 12M dataset (~163GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/flux-1-cc12m-disk.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">COCO dataset</h3>
    <p class="dataset-description">Common Objects in Context dataset (~3.6GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/flux-1-coco.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">FLUX.1 empty encodings</h3>
    <p class="dataset-description">Pre-computed empty encodings for the FLUX.1 benchmark (~2.1MB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/flux-1-empty-encodings.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">All FLUX.1 dataset files</h3>
    <p class="dataset-description">CC12M and COCO, both processed and unprocessed, as well as the COCO 2014 30K validation set (~2.7TB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d flux_1_datasets https://training.mlcommons-storage.org/metadata/flux-1-datasets.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">COCO 2014 30K validation set</h3>
    <p class="dataset-description">Subset of 30,000 image-caption pairs from the COCO 2014 validation data (~2.0MB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d flux_1_datasets https://training.mlcommons-storage.org/metadata/flux-1-coco-2014-val-30k.uri</code>
        </div>
    </div>
</div>
</details>
<details id="graph-neural-network-benchmark"><summary><h3>Graph Neural Network Benchmark</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">IGBH dataset</h3>
    <p class="dataset-description">IGB Heterogenous dataset for the Graph Neural Network benchmark (~2.4TB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/gnn-igbh-dataset-full.uri</code>
        </div>
    </div>
</div>
</details>
<details id="llama-3-1-8b-benchmark"><summary><h3>Llama 3.1 8B Benchmark</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">Llama 3.1 8B preprocessed C4 dataset</h3>
    <p class="dataset-description">Llama 3.1 8B C4 dataset preprocessed with the Llama 3.1 8B tokenizer (~86GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d llama3_1_8b_preprocessed_c4_dataset https://training.mlcommons-storage.org/metadata/llama-3-1-8b-preprocessed-c4-dataset.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Llama 3.1 8B tokenizer</h3>
    <p class="dataset-description">Llama 3.1 8B tokenizer (~33GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d llama3_1_8b_tokenizer https://training.mlcommons-storage.org/metadata/llama-3-1-8b-tokenizer.uri</code>
        </div>
    </div>
</div>
</details>
<details id="llama-3-1-405b-benchmark"><summary><h3>Llama 3.1 405B Benchmark</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">C4 dataset preprocessed with Mixtral tokenizer</h3>
    <p class="dataset-description">C4 dataset for Llama 3.1 405B Benchmark preprocessed with Mixtral tokenizer (~389GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d c4/mixtral_8x22b_preprocessed https://training.mlcommons-storage.org/metadata/mixtral-8x22b-preprocessed-c4-dataset.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Mixtral 8x22b tokenizer</h3>
    <p class="dataset-description">Mixtral 8x22b tokenizer used to preprocess the C4 dataset (~2.8MB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d mixtral_8x22b_tokenizer https://training.mlcommons-storage.org/metadata/mixtral-8x22b-tokenizer.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">C4 full dataset unzipped</h3>
    <p class="dataset-description">Full C4 fileset unzipped, including all raw train and validation files. (~842GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d ./ https://training.mlcommons-storage.org/metadata/c4-full-dataset-unzipped.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">C4 validation dataset zipped</h3>
    <p class="dataset-description">C4 customized validation dataset zipped (~82MB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/c4-validation-dataset-zipped.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">C4 train and eval datasets</h3>
    <p class="dataset-description">C4 train and eval datasets (~842GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d c4/original https://training.mlcommons-storage.org/metadata/c4-train-and-eval-datasets.uri</code>
        </div>
    </div>
</div>
</details>
<details id="bert-benchmark-retired"><summary><h3>BERT Benchmark (Retired)</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">BERT input files</h3>
    <p class="dataset-description">Checkpoint, config, and other input files for the BERT benchmark (~24GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/bert-input-files.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">BERT preprocessed Wikipedia dataset</h3>
    <p class="dataset-description">Wikipedia dataset preprocessed for the BERT benchmark (~9.7GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/bert-preprocessed-wikipedia-dataset.uri</code>
        </div>
    </div>
</div>
</details>
<details id="gpt-3-megatron-benchmark-retired"><summary><h3>GPT-3 Megatron Benchmark (Retired)</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">GPT-3 Megatron preprocessed dataset</h3>
    <p class="dataset-description">C4 dataset preprocessed for the GPT-3 Megatron benchmark (~89GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/gpt-3-megatron-preprocessed-dataset.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">GPT-3 Megatron FP32 checkpoint</h3>
    <p class="dataset-description">FP32 checkpoint for the GPT-3 Megatron benchmark (~2.1TB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/gpt-3-megatron-fp32-checkpoint.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">GPT-3 Megatron BF16 checkpoint</h3>
    <p class="dataset-description">BF16 checkpoint for the GPT-3 Megatron benchmark (~2.5TB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/gpt-3-megatron-bf16-checkpoint.uri</code>
        </div>
    </div>
</div>
</details>
<details id="mixtral-8x22b-benchmark-retired"><summary><h3>Mixtral 8x22b Benchmark (Retired)</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">Mixtral 8x22b v0.1 FSDP checkpoint</h3>
    <p class="dataset-description">Mixtral 8x22b v0.1 FSDP checkpoint for tensor_parallelism=1 (~282GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/mixtral-8x22b-v0-1-fsdp-checkpoint.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Mixtral 8x22b v0.1 2D FSDP TP checkpoint</h3>
    <p class="dataset-description">Mixtral 8x22b v0.1 2D FSDP TP checkpoint for tensor_parallelism&gt;1 (~282GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/mixtral-8x22b-v0-1-2d-fsdp-tp-checkpoint.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Mixtral 8x22b docker images</h3>
    <p class="dataset-description">Mixtral 8x22b docker images for Mixtral 8x22b benchmark environment setup (~24GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://training.mlcommons-storage.org/metadata/mixtral-8x22b-docker-images.uri</code>
        </div>
    </div>
</div>
</details>
<details id="stable-diffusion-benchmark-retired"><summary><h3>Stable Diffusion Benchmark (Retired)</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">Stable Diffusion LAION 400M filtered moments dataset</h3>
    <p class="dataset-description">LAION 400M preprocessed moments for the Stable Diffusion benchmark (~897GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d datasets/laion-400m/webdataset-moments-filtered https://training.mlcommons-storage.org/metadata/stable-diffusion-laion-400m-filtered-moments-dataset.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Stable Diffusion LAION 400M filtered images dataset</h3>
    <p class="dataset-description">LAION 400M raw images for the Stable Diffusion benchmark (~300GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d datasets/laion-400m/webdataset-filtered https://training.mlcommons-storage.org/metadata/stable-diffusion-laion-400m-filtered-images-dataset.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Stable Diffusion COCO 2014 validation prompts dataset</h3>
    <p class="dataset-description">COCO 2014 validation prompts datasetfor the Stable Diffusion benchmark (~2.1MB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d datasets/coco2014 https://training.mlcommons-storage.org/metadata/stable-diffusion-coco2014-validation-prompts-dataset.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Stable Diffusion COCO 2014 validation stats dataset</h3>
    <p class="dataset-description">COCO 2014 validation stats dataset for the Stable Diffusion benchmark (~33MB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d datasets/coco2014 https://training.mlcommons-storage.org/metadata/stable-diffusion-coco2014-validation-stats-dataset.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Stable Diffusion SD checkpoint</h3>
    <p class="dataset-description">StabilityAI's 512-base-ema.ckpt checkpoint for the Stable Diffusion benchmark (~5.3GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d checkpoints/sd https://training.mlcommons-storage.org/metadata/stable-diffusion-sd-checkpoint.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Stable Diffusion Inception checkpoint</h3>
    <p class="dataset-description">Inception checkpoint for the Stable Diffusion benchmark (~96MB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d checkpoints/inception https://training.mlcommons-storage.org/metadata/stable-diffusion-inception-checkpoint.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Stable Diffusion CLIP checkpoint</h3>
    <p class="dataset-description">CLIP checkpoint for the Stable Diffusion benchmark (~3.9GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) -d checkpoints/clip https://training.mlcommons-storage.org/metadata/stable-diffusion-clip-checkpoint.uri</code>
        </div>
    </div>
</div>
</details>

        
        </div>
    </div>
</body>
</html> 