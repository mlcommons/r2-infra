{
  "bucket": "mlcommons-training-wg-public",
  "domain": "training.mlcommons-storage.org",
  "title": "MLPerf Training Benchmark Data Download",
  "index_expandable": "true",
  "datasets": {
    "DLRM v2 Benchmark": [
      {
        "name": "dlrmv2-preprocessed-criteo-click-logs",
        "subpath": "torchrec_dlrm/datasets/preprocessed_criteo_click_logs/",
        "title": "Criteo 4TB multi-hot dataset",
        "description": "Criteo Click Logs dataset preprocessed to create a synthetic multi-hot dataset",
        "size": "4.0TB"
      }
    ],
    "FLUX.1 Benchmark": [
      {
        "name": "flux-1-cc12m-preprocessed",
        "subpath": "flux_1/datasets/cc12m_preprocessed/",
        "title": "CC12M preprocessed dataset",
        "description": "Conceptual 12M preprocessed dataset",
        "size": "2.4TB"
      },
      {
        "name": "flux-1-coco-preprocessed",
        "subpath": "flux_1/datasets/coco_preprocessed/",
        "title": "COCO preprocessed dataset",
        "description": "Common Objects in Context preprocessed dataset",
        "size": "65GB"
      },
      {
        "name": "flux-1-cc12m-disk",
        "subpath": "flux_1/datasets/cc12m_disk/",
        "title": "CC12M dataset",
        "description": "Conceptual 12M dataset",
        "size": "163GB"
      },
      {
        "name": "flux-1-coco",
        "subpath": "flux_1/datasets/coco/",
        "title": "COCO dataset",
        "description": "Common Objects in Context dataset",
        "size": "3.6GB"
      },
      {
        "name": "flux-1-empty-encodings",
        "subpath": "flux_1/datasets/empty_encodings/",
        "title": "FLUX.1 empty encodings",
        "description": "Pre-computed empty encodings for the FLUX.1 benchmark",
        "size": "2.1MB"
      },
      {
        "name": "flux-1-datasets",
        "subpath": "flux_1/datasets/",
        "title": "All FLUX.1 dataset files",
        "description": "CC12M and COCO, both processed and unprocessed, as well as the COCO 2014 30K validation set",
        "destination": "flux_1_datasets",
        "size": "2.7TB"
      },
      {
        "name": "flux-1-coco-2014-val-30k",
        "subpath": "flux_1/datasets/val2014_30k.tsv",
        "title": "COCO 2014 30K validation set",
        "description": "Subset of 30,000 image-caption pairs from the COCO 2014 validation data",
        "destination": "flux_1_datasets",
        "size": "2.0MB"
      }
    ],
    "Graph Neural Network Benchmark": [
      {
        "name": "gnn-igbh-dataset-full",
        "subpath": "graph_neural_network/datasets/igbh/",
        "title": "IGBH dataset",
        "description": "IGB Heterogenous dataset for the Graph Neural Network benchmark",
        "size": "2.4TB"
      }
    ],
    "Llama 3.1 8B Benchmark": [
      {
        "name": "llama-3-1-8b-preprocessed-c4-dataset",
        "subpath": "llama3_1/datasets/c4/llama3_1_8b/",
        "title": "Llama 3.1 8B preprocessed C4 dataset",
        "description": "Llama 3.1 8B C4 dataset preprocessed with the Llama 3.1 8B tokenizer",
        "destination": "llama3_1_8b_preprocessed_c4_dataset",
        "size": "86GB"
      },
      {
        "name": "llama-3-1-8b-tokenizer",
        "subpath": "llama3_1/tokenizers/llama3_1_8b/",
        "title": "Llama 3.1 8B tokenizer",
        "description": "Llama 3.1 8B tokenizer",
        "destination": "llama3_1_8b_tokenizer",
        "size": "33GB"
      }
    ],
    "Llama 3.1 405B Benchmark": [
      {
        "name": "mixtral-8x22b-preprocessed-c4-dataset",
        "subpath": "common/datasets/c4/mixtral_8x22b_preprocessed/",
        "title": "C4 dataset preprocessed with Mixtral tokenizer",
        "description": "C4 dataset for Llama 3.1 405B Benchmark preprocessed with Mixtral tokenizer",
        "destination": "c4/mixtral_8x22b_preprocessed",
        "size": "389GB"
      },
      {
        "name": "mixtral-8x22b-tokenizer",
        "subpath": "common/tokenizers/mixtral_8x22b/",
        "title": "Mixtral 8x22b tokenizer",
        "description": "Mixtral 8x22b tokenizer used to preprocess the C4 dataset",
        "destination": "mixtral_8x22b_tokenizer",
        "size": "2.8MB"
      },
      {
        "name": "c4-full-dataset-unzipped",
        "subpath": "common/datasets/c4/original/en_json/3.0.1/",
        "title": "C4 full dataset unzipped",
        "description": "Full C4 fileset unzipped, including all raw train and validation files.",
        "destination": "./",
        "size": "842GB"
      },
      {
        "name": "c4-validation-dataset-zipped",
        "subpath": "common/datasets/c4/original/c4-validation-91205-samples.en.json.gz",
        "title": "C4 validation dataset zipped",
        "description": "C4 customized validation dataset zipped",
        "size": "82MB"
      },
      {
        "name": "c4-train-and-eval-datasets",
        "subpath": "common/datasets/c4/original/",
        "title": "C4 train and eval datasets",
        "description": "C4 train and eval datasets",
        "destination": "c4/original",
        "size": "842GB"
      }
    ],
    "BERT Benchmark (Retired)": [
      {
        "name": "bert-input-files",
        "subpath": "wikipedia_for_bert/input_files/",
        "title": "BERT input files",
        "description": "Checkpoint, config, and other input files for the BERT benchmark",
        "size": "24GB"
      },
      {
        "name": "bert-preprocessed-wikipedia-dataset",
        "subpath": "wikipedia_for_bert/processed_dataset/",
        "title": "BERT preprocessed Wikipedia dataset",
        "description": "Wikipedia dataset preprocessed for the BERT benchmark",
        "size": "9.7GB"
      }
    ],
    "GPT-3 Megatron Benchmark (Retired)": [
      {
        "name": "gpt-3-megatron-preprocessed-dataset",
        "subpath": "gpt3/megatron-lm/dataset_c4_spm.tar",
        "title": "GPT-3 Megatron preprocessed dataset",
        "description": "C4 dataset preprocessed for the GPT-3 Megatron benchmark",
        "size": "89GB"
      },
      {
        "name": "gpt-3-megatron-fp32-checkpoint",
        "subpath": "gpt3/megatron-lm/checkpoint_megatron_fp32.tar",
        "title": "GPT-3 Megatron FP32 checkpoint",
        "description": "FP32 checkpoint for the GPT-3 Megatron benchmark",
        "size": "2.1TB"
      },
      {
        "name": "gpt-3-megatron-bf16-checkpoint",
        "subpath": "gpt3/megatron-lm/checkpoint_nemo_bf16.tar",
        "title": "GPT-3 Megatron BF16 checkpoint",
        "description": "BF16 checkpoint for the GPT-3 Megatron benchmark",
        "size": "2.5TB"
      }
    ],
    "Mixtral 8x22b Benchmark (Retired)": [
      {
        "name": "mixtral-8x22b-v0-1-fsdp-checkpoint",
        "subpath": "mixtral_8x22b/checkpoints/Mixtral-8x22B-v0.1-fsdp/",
        "title": "Mixtral 8x22b v0.1 FSDP checkpoint",
        "description": "Mixtral 8x22b v0.1 FSDP checkpoint for tensor_parallelism=1",
        "size": "282GB"
      },
      {
        "name": "mixtral-8x22b-v0-1-2d-fsdp-tp-checkpoint",
        "subpath": "mixtral_8x22b/checkpoints/Mixtral-8x22B-v0.1-2d-fsdp-tp/",
        "title": "Mixtral 8x22b v0.1 2D FSDP TP checkpoint",
        "description": "Mixtral 8x22b v0.1 2D FSDP TP checkpoint for tensor_parallelism>1",
        "size": "282GB"
      },
      {
        "name": "mixtral-8x22b-docker-images",
        "subpath": "mixtral_8x22b/docker-images/",
        "title": "Mixtral 8x22b docker images",
        "description": "Mixtral 8x22b docker images for Mixtral 8x22b benchmark environment setup",
        "size": "24GB"
      }
    ],
    "Stable Diffusion Benchmark (Retired)": [
      {
        "name": "stable-diffusion-laion-400m-filtered-moments-dataset",
        "subpath": "stable_diffusion/datasets/laion-400m/moments-webdataset-filtered/",
        "title": "Stable Diffusion LAION 400M filtered moments dataset",
        "description": "LAION 400M preprocessed moments for the Stable Diffusion benchmark",
        "metadata_override": "true",
        "size": "897GB"
      },
      {
        "name": "stable-diffusion-laion-400m-filtered-images-dataset",
        "subpath": "stable_diffusion/datasets/laion-400m/images-webdataset-filtered/",
        "title": "Stable Diffusion LAION 400M filtered images dataset",
        "description": "LAION 400M raw images for the Stable Diffusion benchmark",
        "metadata_override": "true",
        "size": "300GB"
      }
    ]
  }
}
