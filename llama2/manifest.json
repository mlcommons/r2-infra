{
  "bucket": "mlcommons-llama2",
  "domain": "llama2.mlcommons-storage.org",
  "title": "MLCommons Llama 2 Download",
  "license_notice": "Llama 2 models are provided to MLCommons Members for use in MLPerf benchmarks under the terms of <a href='https://llama2.mlcommons-storage.org/data/MLCommons_-_Meta_Platforms%2C_Inc._-_Letter_Agreement_to_Llama_License_-_12.05.2023%20-%20signed.pdf' target='_blank'>this side letter</a> from Meta.",
  "index_expandable": "true",
  "datasets": {
    "Inference Models": [
      {
        "name": "llama-2-7b-chat-hf",
        "subpath": "data/Llama-2-7b-chat-hf/",
        "title": "Llama 2 7B Parameter Model",
        "description": "Pre-converted Hugging Face checkpoints for the Llama 2 7B parameter chat model",
        "size": "54GB"
      },
      {
        "name": "llama-2-70b-chat-hf",
        "subpath": "data/Llama-2-70b-chat-hf/",
        "title": "Llama 2 70B Parameter Model",
        "description": "Pre-converted Hugging Face checkpoints for the Llama 2 70B parameter chat model",
        "size": "552GB"
      }
    ],
    "Training Models": [
      {
        "name": "llama-2-70b-fused-qkv-mlperf",
        "subpath": "data/Llama2-70b-fused-qkv-mlperf/",
        "title": "Llama 2 70B Parameter Fused QKV MLPerf Model",
        "description": "Llama 2 70B parameter fused QKV MLPerf model",
        "size": "276GB"
      }
    ],
    "Training Data": [
      {
        "name": "scrolls-gov-report-8k",
        "subpath": "data/training/scrolls_gov_report_8k/",
        "title": "Scrolls Gov Report 8k",
        "description": "Preprocessed Scrolls Gov Report 8k dataset for the Llama 2 Training benchmark",
        "size": "112MB"
      }
    ],
    "Quantized Models (via NVIDIA TensorRT-LLM)": [
      {
        "name": "llama2-70b-chat-hf-tp2pp1-fp8",
        "subpath": "data/quantized/fp8-quantized-ammo/llama2-70b-chat-hf-tp2pp1-fp8/",
        "title": "Llama 2 70B Parameter Quantized Model (FP8 TP2PP1)",
        "description": "A version of the Llama 2 70B parameter chat model quantized to FP8 with TP2PP1",
        "size": "70GB"
      },
      {
        "name": "llama2-70b-chat-hf-tp1pp1-fp8",
        "subpath": "data/quantized/fp8-quantized-ammo/llama2-70b-chat-hf-tp1pp1-fp8/",
        "title": "Llama 2 70B Parameter Quantized Model (FP8 TP1PP1)",
        "description": "A version of the Llama 2 70B parameter chat model quantized to FP8 with TP1PP1",
        "size": "70GB"
      },
      {
        "name": "llama2-70b-chat-hf-tp1pp2-fp8",
        "subpath": "data/quantized/fp8-quantized-ammo/llama2-70b-chat-hf-tp1pp2-fp8/",
        "title": "Llama 2 70B Parameter Quantized Model (FP8 TP1PP2)",
        "description": "A version of the Llama 2 70B parameter chat model quantized to FP8 with TP1PP2",
        "size": "70GB"
      }
    ]
  }
}

