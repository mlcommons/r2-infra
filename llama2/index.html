<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MLCommons Llama 2 Download</title>
    
    <!-- Favicons -->
    <link rel="apple-touch-icon" sizes="180x180" href="https://r2-infra.mlcommons-storage.org/central/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://r2-infra.mlcommons-storage.org/central/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://r2-infra.mlcommons-storage.org/central/favicon/favicon-16x16.png">
    <link rel="manifest" href="https://r2-infra.mlcommons-storage.org/central/favicon/site.webmanifest">
    
    <!-- Load shared CSS and JS from central bucket -->
    <link rel="stylesheet" href="https://r2-infra.mlcommons-storage.org/central/shared.css">
    <script src="https://r2-infra.mlcommons-storage.org/central/shared.js"></script>
    <!-- Load shared header & quick-start as early as possible -->
    <script defer>
      document.addEventListener('DOMContentLoaded', () => {
        fetch('https://r2-infra.mlcommons-storage.org/central/shared-content.html')
          .then(r => r.text())
          .then(html => {
            const tmp = document.createElement('div');
            tmp.innerHTML = html;
            const header = tmp.querySelector('.header-strip');
            const quick  = tmp.querySelector('#quick-start-section');
            if (header) document.getElementById('header-placeholder').innerHTML = header.outerHTML;
            const holder=document.getElementById('quick-start-placeholder');
            if(quick && holder){ holder.replaceWith(quick); }
            if (typeof initializeCopyButtons === 'function') initializeCopyButtons();
          })
          .catch(err => console.error('Failed to load shared content:', err));
      });
    </script>
</head>
<body>
    <!-- Header will be loaded from shared content -->
    <div id="header-placeholder"></div>
    
    <div class="page-content">
        <div class="container">
            <h1>MLCommons Llama 2 Download</h1>
            
            <div class="alert alert-info"><strong>Licensing Notice:</strong> Llama 2 models are provided to MLCommons Members for use in MLPerf benchmarks under the terms of <a href='https://llama2.mlcommons-storage.org/data/MLCommons_-_Meta_Platforms%2C_Inc._-_Letter_Agreement_to_Llama_2_License_(9.9.2024)_-_signed.pdf' target='_blank'>this side letter</a> from Meta.</div>


            <!-- Quick-Start skeleton to reserve space (visibility hidden) -->
            <div id="quick-start-placeholder" style="visibility:hidden">
                <div class="alert alert-info">
                    <strong>Quick Start:</strong> Copy one of the commands below and run it in your terminal to download the indicated dataset.
                </div>
            </div>
        
            <h2>Available Downloads</h2>

            <details><summary><h3>Inference Models</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">Llama 2 7B Parameter Model</h3>
    <p class="dataset-description">Pre-converted Hugging Face checkpoints for the Llama 2 7B parameter chat model (~54GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://llama2.mlcommons-storage.org/metadata/llama-2-7b-chat-hf.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Llama 2 70B Parameter Model</h3>
    <p class="dataset-description">Pre-converted Hugging Face checkpoints for the Llama 2 70B parameter chat model (~552GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://llama2.mlcommons-storage.org/metadata/llama-2-70b-chat-hf.uri</code>
        </div>
    </div>
</div>
</details>
<details><summary><h3>Training Models</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">Llama 2 70B Parameter Fused QKV MLPerf Model</h3>
    <p class="dataset-description">Llama 2 70B parameter fused QKV MLPerf model (~276GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://llama2.mlcommons-storage.org/metadata/llama-2-70b-fused-qkv-mlperf.uri</code>
        </div>
    </div>
</div>
</details>
<details><summary><h3>Training Data</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">Scrolls Gov Report 8k</h3>
    <p class="dataset-description">Preprocessed Scrolls Gov Report 8k dataset for the Llama 2 Training benchmark (~112MB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://llama2.mlcommons-storage.org/metadata/scrolls-gov-report-8k.uri</code>
        </div>
    </div>
</div>
</details>
<details><summary><h3>Quantized Models</h3> (click to expand)</summary>
<div class="dataset-section">
    <h3 class="dataset-title">Llama 2 70B Parameter Quantized Model (FP8 TP2PP1)</h3>
    <p class="dataset-description">A version of the Llama 2 70B parameter chat model quantized to FP8 with TP2PP1 (~70GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://llama2.mlcommons-storage.org/metadata/llama2-70b-chat-hf-tp2pp1-fp8.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Llama 2 70B Parameter Quantized Model (FP8 TP1PP1)</h3>
    <p class="dataset-description">A version of the Llama 2 70B parameter chat model quantized to FP8 with TP1PP1 (~70GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://llama2.mlcommons-storage.org/metadata/llama2-70b-chat-hf-tp1pp1-fp8.uri</code>
        </div>
    </div>
</div>
<div class="dataset-section">
    <h3 class="dataset-title">Llama 2 70B Parameter Quantized Model (FP8 TP1PP2)</h3>
    <p class="dataset-description">A version of the Llama 2 70B parameter chat model quantized to FP8 with TP1PP2 (~70GB)</p>
    <div class="command-section">
        <div class="code-block">
            <code>bash <(curl -s https://raw.githubusercontent.com/mlcommons/r2-downloader/refs/heads/main/mlc-r2-downloader.sh) https://llama2.mlcommons-storage.org/metadata/llama2-70b-chat-hf-tp1pp2-fp8.uri</code>
        </div>
    </div>
</div>
</details>

        
        </div>
    </div>
</body>
</html> 