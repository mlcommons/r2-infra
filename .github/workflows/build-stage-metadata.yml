name: Build, commit, and stage metadata files

on:
  pull_request:
    branches: [ main ]
    types: [ opened, synchronize, reopened ]
    paths:
      - '*/manifest.json'
      - '*/index.html'
      - '.github/workflows/build-stage-metadata.yml'

# Prevent overlapping runs on the same PR/branch
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: ${{ github.actor != 'mlc-r2-infra[bot]' }}

jobs:
  generate-metadata:
    if: github.actor != 'mlc-r2-infra[bot]'
    runs-on: ubuntu-latest
    environment: staging-metadata
    permissions:
      contents: read       # allow checking out the repository
      issues: write        # allow workflow to post/update PR comments
      pull-requests: write # needed for PR comment APIs when using pull_request event

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref }}
          persist-credentials: false

      - name: Get changed directories with manifests
        id: changed_dirs
        run: |
          echo "Fetching base branch main..."
          git fetch origin main --depth=1
          echo "Finding changed files against main..."
          CHANGED_FILES=$(git diff --name-only origin/main HEAD)
          echo "Changed files list:"
          echo "$CHANGED_FILES"
          # Get unique directories from changed files
          CHANGED_DIRS=""
          if [ -n "$CHANGED_FILES" ]; then
            CHANGED_DIRS=$(echo "$CHANGED_FILES" | xargs -n1 dirname | sort -u)
          fi
          echo "Unique changed directories:"
          echo "$CHANGED_DIRS"
          # Filter for directories that contain a manifest.json and create a list of manifest files
          MANIFEST_FILES=""
          if [ -n "$CHANGED_DIRS" ]; then
            for dir in $CHANGED_DIRS; do
              if [ -f "$dir/manifest.json" ]; then
                MANIFEST_FILES="$MANIFEST_FILES $dir/manifest.json"
              fi
            done
          fi
          # Trim leading space if any
          MANIFEST_FILES=$(echo "$MANIFEST_FILES" | sed 's/^ *//')
          echo "Manifests to process: [$MANIFEST_FILES]"
          echo "manifest_files=$MANIFEST_FILES" >> $GITHUB_OUTPUT

      - name: Load R2 secrets from 1Password
        if: steps.changed_dirs.outputs.manifest_files != ''
        id: op-load-secret
        uses: 1password/load-secrets-action@v3
        env:
          OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.OP_SERVICE_ACCOUNT_TOKEN }}
          R2_ACCESS_KEY_ID: op://mqgmk3badhri6yvwi3qknilwz4/hjinzlouv5hekttyckgij4iyqq/f6gocg2smekpszwxqpnn7x6jga/vsktfcerr4lzwelblqsdzio5ku
          R2_SECRET_ACCESS_KEY: op://mqgmk3badhri6yvwi3qknilwz4/hjinzlouv5hekttyckgij4iyqq/f6gocg2smekpszwxqpnn7x6jga/ddid5yjvyyzobwvxghauuxs4vu
          R2_ENDPOINT: op://mqgmk3badhri6yvwi3qknilwz4/hjinzlouv5hekttyckgij4iyqq/f6gocg2smekpszwxqpnn7x6jga/cwrkc6c564ds47q3ofajxgzkaa
          APP_PRIVATE_KEY: "op://mqgmk3badhri6yvwi3qknilwz4/v7kvdlzwlj23nf6r4r5t3taf2e/private key"
          APP_ID: "op://mqgmk3badhri6yvwi3qknilwz4/v7kvdlzwlj23nf6r4r5t3taf2e/App ID"

      - name: Install rclone
        if: steps.changed_dirs.outputs.manifest_files != ''
        run: |
          sudo -v ; curl https://rclone.org/install.sh | sudo bash
          rclone version

      - name: Configure temporary rclone remote
        if: steps.changed_dirs.outputs.manifest_files != ''
        run: |
          rclone config create r2-meta s3 \
            provider=Cloudflare \
            access_key_id="${{ steps.op-load-secret.outputs.R2_ACCESS_KEY_ID }}" \
            secret_access_key="${{ steps.op-load-secret.outputs.R2_SECRET_ACCESS_KEY }}" \
            endpoint="${{ steps.op-load-secret.outputs.R2_ENDPOINT }}" \
            no_check_bucket=true --non-interactive
          rclone listremotes

      - name: Generate metadata files for datasets
        if: steps.changed_dirs.outputs.manifest_files != ''
        run: |
          set -euo pipefail

          # File that will store per-dataset size info for later use in the PR comment
          SIZE_FILE="$GITHUB_WORKSPACE/size_report.txt"
          echo "folder,dataset,files,bytes,hr" > "$SIZE_FILE"

          for json in ${{ steps.changed_dirs.outputs.manifest_files }}; do
            # Skip central resources folder if present
            [[ "$json" == "central/manifest.json" ]] && continue

            folder="$(dirname "$json")"  # e.g., 'waymo'
            META_DIR="${folder}/metadata"
            mkdir -p "$META_DIR"

            ROOT_BUCKET=$(jq -r '.bucket' "$json")
            ROOT_DOMAIN=$(jq -r '.domain' "$json")

            echo "ðŸ“‚ Processing $folder (bucket: $ROOT_BUCKET)"

            mapfile -t DATASETS < <(jq -c '.datasets | values | .[][]' "$json")
            for dataset in "${DATASETS[@]}"; do
              name=$(echo "$dataset" | jq -r '.name')
              subpath=$(echo "$dataset" | jq -r '.subpath')
              metadata_override=$(echo "$dataset" | jq -r '.metadata_override // false')

              # Trim possible trailing slash from subpath for bucket path
              clean_subpath="${subpath%/}"
              bucket_path="$ROOT_BUCKET/$clean_subpath"

              # Generate metadata files and collect size unless metadata_override is true
              if [[ "$metadata_override" != "true" ]]; then
                # It's a directory if the original subpath ends with a slash.
                # Otherwise, we assume it's a file.
                if [[ "$subpath" == */ ]]; then
                  uri_path="$clean_subpath"
                  echo "    (subpath is a directory)"
                else
                  uri_path=$(dirname "$clean_subpath")
                  echo "    (subpath is a file)"
                fi
                
                # Construct the final URI.
                if [[ "$uri_path" == "." || -z "$uri_path" ]]; then
                  uri="https://${ROOT_DOMAIN}"
                else
                  uri="https://${ROOT_DOMAIN}/${uri_path%/}"
                fi

                echo "  â€¢ Generating .uri for $name => $uri"
                echo "$uri" > "$META_DIR/${name}.uri"

                echo "    Generating .md5 for $name from $bucket_path (sorted)"
                if ! rclone md5sum "r2-meta:${bucket_path}" | LC_ALL=C sort > "$META_DIR/${name}.md5"; then
                  echo "::error::Failed to generate MD5 list for ${name} (folder: $folder). Aborting."
                  exit 1
                fi

                # Collect dataset size information for PR comment
                size_json=$(rclone size --json "r2-meta:${bucket_path}" || echo '{}')
                files=$(echo "$size_json" | jq -r '.count // 0')
                bytes=$(echo "$size_json" | jq -r '.bytes // 0')
                if command -v numfmt >/dev/null; then
                  # Use base-10 SI units so sizes show as MB/GB/TB instead of MiB/GiB/TiB
                  hr=$(numfmt --to=si --suffix=B "${bytes}" 2>/dev/null || echo "${bytes}B")
                else
                  hr="${bytes}B"
                fi
                echo "${folder},${name},${files},${bytes},${hr}" >> "$SIZE_FILE"

                # Add size to manifest.json
                echo "    ðŸ“ Adding size '${hr}' to ${json} for dataset '${name}'"
                tmp_json=$(mktemp)
                jq --arg name "$name" --arg size "$hr" \
                  '(.datasets | .. | objects | select(.name == $name)) |= . + {"size": $size}' \
                  "$json" > "$tmp_json" && mv "$tmp_json" "$json"
              else
                echo "  â€¢ Skipping metadata generation and size calculation for $name (metadata_override: true)"
                
                # For datasets with metadata_override, get the existing size from the JSON for PR comment
                existing_size=$(echo "$dataset" | jq -r '.size // "unknown"')
                if [[ "$existing_size" != "unknown" && "$existing_size" != "null" && -n "$existing_size" ]]; then
                  echo "${folder},${name},bypassed,bypassed,${existing_size}" >> "$SIZE_FILE"
                else
                  echo "${folder},${name},bypassed,bypassed,size not specified" >> "$SIZE_FILE"
                fi
              fi
            done
          done

      - name: Upload staging metadata files to R2 buckets
        if: steps.changed_dirs.outputs.manifest_files != ''
        run: |
          set -euo pipefail

          echo "ðŸ”„ Uploading staging metadata files (.uri and .md5) to R2 buckets..."

          PR_NUM="${{ github.event.number }}"

          for json in ${{ steps.changed_dirs.outputs.manifest_files }}; do
            # Skip central resources folder if present
            [[ "$json" == "central/manifest.json" ]] && continue

            folder="$(dirname "$json")"
            ROOT_BUCKET=$(jq -r '.bucket' "$json")

            mapfile -t DATASETS < <(jq -c '.datasets | values | .[][]' "$json")
            for dataset in "${DATASETS[@]}"; do
              name=$(echo "$dataset" | jq -r '.name')
              subpath=$(echo "$dataset" | jq -r '.subpath')
              clean_subpath="${subpath%/}"

              bucket_path="$ROOT_BUCKET/$clean_subpath"
              META_DIR="${folder}/metadata"

              echo "ðŸ“¤ ${folder}/${name}: copying to r2-meta:${ROOT_BUCKET}/metadata/staging-${PR_NUM}-${name}.{uri,md5}"

              # Upload URI and MD5 files with staging-<PR>- prefix into bucket-level metadata dir
              rclone copyto "${META_DIR}/${name}.uri" "r2-meta:${ROOT_BUCKET}/metadata/staging-${PR_NUM}-${name}.uri" \
                --header-upload "Content-Type: text/plain; charset=utf-8" -v

              rclone copyto "${META_DIR}/${name}.md5" "r2-meta:${ROOT_BUCKET}/metadata/staging-${PR_NUM}-${name}.md5" \
                --header-upload "Content-Type: text/plain; charset=utf-8" -v
            done
          done

          echo "âœ… Staging metadata upload complete."

      - name: Generate GitHub App token
        if: steps.changed_dirs.outputs.manifest_files != ''
        id: app-token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ steps.op-load-secret.outputs.APP_ID }}
          private-key: ${{ steps.op-load-secret.outputs.APP_PRIVATE_KEY }}

      - name: Commit and push metadata files
        if: steps.changed_dirs.outputs.manifest_files != ''
        run: |
          git config user.name "mlc-r2-infra[bot]"
          git config user.email "218688909+mlc-r2-infra[bot]@users.noreply.github.com"

          # Ensure all subsequent git operations (commit, fetch) use the App token
          git remote set-url origin "https://x-access-token:${{ steps.app-token.outputs.token }}@github.com/${{ github.repository }}.git"

          git add */manifest.json
          git add */metadata/*
          git diff --cached --name-status
          if git diff --cached --quiet; then
            echo "No metadata changes to commit."
          else
            git commit -m "Commit metadata files (auto-generated by workflow)" || true
            
            # Pull latest changes and rebase if necessary to avoid conflicts
            echo "Pulling latest changes before pushing..."
            git pull --rebase origin "${GITHUB_HEAD_REF}" || {
              echo "Rebase failed, trying merge strategy..."
              git rebase --abort 2>/dev/null || true
              git pull origin "${GITHUB_HEAD_REF}"
            }
            
            git push origin HEAD:"${GITHUB_HEAD_REF}"
          fi

      - name: Comment PR with metadata generation summary
        if: steps.changed_dirs.outputs.manifest_files != ''
        uses: actions/github-script@v7
        env:
          GITHUB_TOKEN: ${{ steps.app-token.outputs.token }}
        with:
          script: |
            const { execSync } = require('child_process');
            // Fetch main for comparison
            execSync('git fetch --depth=1 origin main');
            const diff = execSync('git diff --name-only origin/main HEAD -- "*/metadata/*.uri" "*/metadata/*.md5"').toString().trim();
            const files = diff ? diff.split('\n') : [];
            const manifestDiff = execSync('git diff --name-only origin/main HEAD -- "*/manifest.json"').toString().trim();
            const manifestFiles = manifestDiff ? manifestDiff.split('\n') : [];
            const allFiles = [...manifestFiles, ...files].filter(Boolean);
            const uniqueFiles = [...new Set(allFiles)];

            let body = '## ðŸ“ Metadata files built and staged\n\n';
            if (uniqueFiles.length) {
              body += '### ðŸ”„ Metadata and manifest files changed vs `main`\n';
              uniqueFiles.forEach(f => body += `- \`${f}\`\n`);
            } else {
              body += 'No metadata or manifest file changes compared to main.';
            }

            // Append dataset-size table if available
            const fs = require('fs');
            try {
              const raw = fs.readFileSync('size_report.txt', 'utf8').trim().split('\n').slice(1); // drop header
              if (raw.length) {
                body += '\n\n### ðŸ“¦ Relevant dataset information\n\n| Folder | Dataset | Files | Size |\n| ------ | ------- | ----- | ---- |\n';
                raw.forEach(line => {
                  const [folder, dataset, files, bytes, hr] = line.split(',');
                  body += `| ${folder} | ${dataset} | ${files} | ${hr} |\n`;
                });
              }
            } catch (e) {
              // size_report.txt not found â€“ ignore
            }

            body += '\n---\n*ðŸ¤– This comment was automatically generated by the build-stage-metadata workflow.*';

            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existing = comments.data.find(c => c.user.type === 'Bot' && c.body.includes('Metadata files built and staged'));

            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body,
              });
            }